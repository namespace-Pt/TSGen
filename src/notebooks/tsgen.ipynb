{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-03 07:43:15,463] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-03 07:43:16,245] INFO (Config) setting seed to 42...\n",
      "[2024-04-03 07:43:16,250] INFO (Config) setting PLM to t5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading t5-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/peitian/Envs/adon/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "[2024-04-03 07:43:26,151] INFO (Config) Config: {'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'batch_size': 2, 'bf16': False, 'cache_root': 'data/cache/NQ320k', 'data_format': 'memmap', 'data_root': '/data/TSGen', 'dataset': 'NQ320k', 'debug': False, 'deepspeed': None, 'device': 0, 'distill_src': 'none', 'early_stop_patience': 5, 'enable_all_gather': True, 'enable_distill': False, 'enable_inbatch_negative': True, 'epoch': 20, 'eval_batch_size': 2, 'eval_delay': 0, 'eval_flops': False, 'eval_metric': ['mrr', 'recall'], 'eval_metric_cutoff': [1, 5, 10, 100, 1000], 'eval_mode': 'retrieve', 'eval_posting_length': False, 'eval_set': 'dev', 'eval_step': '1e', 'fp16': False, 'grad_accum_step': 1, 'hits': 1000, 'index_shard': 32, 'index_thread': 10, 'index_type': 'invvec', 'learning_rate': 3e-06, 'load_ckpt': None, 'load_encode': False, 'load_index': True, 'load_query_encode': False, 'load_result': False, 'load_text_encode': False, 'loader_train': 'neg', 'main_metric': 'Recall@10', 'max_grad_norm': 0, 'max_query_length': 64, 'max_step': 0, 'max_text_length': 512, 'mode': 'train', 'model_type': None, 'neg_type': 'random', 'nneg': 1, 'num_worker': 0, 'parallel': 'text', 'plm': 't5', 'plm_dir': '/data/TSGen/PLMs/t5', 'plm_root': '/data/TSGen/PLMs', 'plm_tokenizer': 't5', 'posting_prune': 0.0, 'query_gate_k': 0, 'query_length': 32, 'report_to': 'none', 'return_first_mask': False, 'return_special_mask': False, 'save_at_eval': False, 'save_ckpt': 'best', 'save_encode': False, 'save_index': True, 'save_model': False, 'save_res': 'retrieval_result', 'save_score': False, 'scheduler': 'constant', 'seed': 42, 'special_token_ids': {'cls': (None, None), 'pad': ('<pad>', 0), 'unk': ('<unk>', 2), 'sep': (None, None), 'eos': ('</s>', 1)}, 'text_col': [1, 2, 3], 'text_col_sep': ' ', 'text_gate_k': 0, 'text_length': 512, 'text_type': 'default', 'train_set': ['train'], 'untie_encoder': False, 'verifier_hits': 1000, 'verifier_index': 'none', 'verifier_src': 'none', 'verifier_type': 'none', 'vocab_size': 32100, 'warmup_ratio': 0.1, 'warmup_step': 0, 'weight_decay': 0.01}\n",
      "[2024-04-03 07:43:26,242] INFO (Dataset) initializing NQ320k memmap Text dataset...\n",
      "[2024-04-03 07:43:26,293] INFO (Dataset) initializing NQ320k memmap Query dev dataset...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "if sys.path[-1] != \"../\":\n",
    "    sys.path.append(\"../\")\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "os.environ['https_proxy'] = \"http://127.0.0.1:15777\"\n",
    "os.environ['http_proxy'] = \"http://127.0.0.1:15777\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from random import sample\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import torch\n",
    "from utils.util import *\n",
    "from utils.index import *\n",
    "from utils.data import *\n",
    "\n",
    "from hydra import initialize, compose\n",
    "\n",
    "config = Config()\n",
    "with initialize(version_base=None, config_path=\"../data/config/\"):\n",
    "    overrides = [\n",
    "        \"base=NQ320k\",\n",
    "        # \"base=MS300k\",\n",
    "        # \"++plm=t5\",\n",
    "    ]\n",
    "    hydra_config = compose(config_name=\"_example\", overrides=overrides)\n",
    "    config._from_hydra(hydra_config)\n",
    "\n",
    "loaders = prepare_data(config)\n",
    "\n",
    "loader_text = loaders[\"text\"]\n",
    "loader_query = loaders[\"query\"]\n",
    "text_dataset = loader_text.dataset\n",
    "query_dataset = loader_query.dataset\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(os.path.join(config.plm_root, config.plm_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load terms\n",
    "code_type = \"term\"\n",
    "code_tokenizer = \"t5\"\n",
    "# for NQ320k\n",
    "code_length = 26\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(config.plm_root, code_tokenizer))\n",
    "\n",
    "text_codes = np.memmap(\n",
    "    f\"data/cache/{config.dataset}/codes/{code_type}/{code_tokenizer}/{code_length}/codes.mmp\",\n",
    "    mode=\"r\",\n",
    "    dtype=np.int32\n",
    ").reshape(len(text_dataset), -1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> email, mail, marketing, sent, messages, customer, sending, hide, purpose, opt, online, merchant,</s>',\n",
       " '<pad> mother, ted, umbrella, met, meet, tracy, mcconnell, mom,</s><pad>',\n",
       " '<pad> sperm, fertilization, spermatozoon, vitro, spermatozoa, egg,</s>',\n",
       " '<pad> quarterback, nfl, wins, career, brady, football, peyton, manning,</s>',\n",
       " '<pad> roanoke, colony, lost, disappeared, dare, raleigh, established,</s>',\n",
       " '<pad> africa, african, regions, five, subregions, west, north, six, south, continent,</s><pad>',\n",
       " '<pad> mantis, guardians, actress, french, galaxy, spring, infinity, hacker, sleepless,</s>',\n",
       " '<pad> frosty, december, hat, christmas, melt, snowman, life, 1969, special,</s>',\n",
       " '<pad> acadians, acadia, french, colonial, acadiens,</s><pad>',\n",
       " '<pad> banks, outer, graveyard, carolina, roanoke, islands, wright,</s>']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Email marketing Email marketing is the act of sending a commercial message, typically to a group of people, using email. In its broadest sense, every email sent to a potential or current customer could be considered email marketing. It usually involves using email to send advertisements, request business, or solicit sales or donations, and is meant to build loyalty, trust, or brand awareness. Marketing emails can be sent to a purchased lead list',\n",
       " \"The Mother ( How I Met Your Mother ) Tracy McConnell, better known as <unk> The Mother '', is the title character from the CBS television sitcom How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The Mother. Tracy McConnell appears in 8 episodes from <unk> Lucky Penny '' to <unk> The Time Travelers '' as\",\n",
       " 'Human fertilization Human fertilization is the union of a human egg and sperm, usually occurring in the ampulla of the fallopian tube. The result of this union is the production of a zygote cell, or fertilized egg, initiating prenatal development. Scientists discovered the dynamics of human fertilization in the nineteenth century. The process of fertilization involves a sperm fusing with an ov',\n",
       " 'List of National Football League career quarterback wins leaders The following is a list of the top National Football League ( NFL ) quarterbacks in wins. In the NFL, the quarterback is the only position that is credited with records of wins and losses. Active quarterback Tom Brady holds the records for most wins with 220, most regular season wins with 195, and most postseason wins with 25, as of Week 16 of the 2017 NFL season. Having',\n",
       " \"Roanoke Colony The Roanoke Colony ( / <unk>ro<unk>no<unk>k / ), also known as the Lost Colony, was established in 1585 on Roanoke Island in what is today's Dare County, North Carolina. It was a late 16th - century attempt by Queen Elizabeth I to establish a permanent English settlement in North America. The colony\",\n",
       " 'List of regions of Africa The continent of Africa is commonly divided into five regions or subregions, four of which are in Sub-Saharan Africa, though some definitions may contain four ( removing Central Africa ) or six regions ( separating the horn of Africa into its own region ). Contents ( hide ) 1 List of subregions in Africa 2 Directional approach 3 Physiographic approach 4 Linguistic approach 4.1 By official',\n",
       " \"Pom Klementieff Pom Klementieff ( born 3 May 1986 ) is a French actress. She was trained at the Cours Florent drama school in Paris and has appeared in such films as Loup ( 2009 ), Sleepless Night ( 2011 ) and Hacker's Game ( 2015 ). She plays the role of Mantis in the film Guardians of the Galaxy Vol. 2 ( 2017 ) and will appear\",\n",
       " \"Frosty the Snowman ( film ) Frosty the Snowman is a 1969 animated Christmas television special based on the song <unk> Frosty the Snowman ''. The program, which first aired on December 7, 1969 on CBS ( where it continues to air annually ), was produced for television by Rankin / Bass Productions and featured the voices of comedians Jimmy Durante as the film's narr\",\n",
       " 'History of the Acadians The Acadians ( French : Acadiens ) are the descendants of the French settlers, and sometimes the Indigenous peoples, of parts of Acadia ( French : Acadie ) in the northeastern region of North America comprising what is now the Canadian Maritime Provinces of New Brunswick, Nova Scotia, and Prince Edward Island, GaspÃ©, in Quebec, and to the',\n",
       " 'Outer Banks The Outer Banks ( OBX ) is a 200 - mile - long ( 320 km ) string of barrier islands and spits off the coast of North Carolina and southeastern Virginia, on the east coast of the United States. They cover most of the North Carolina coastline, separating the Currituck Sound, Albemarle Sound, and Pamlico Sound from the Atlantic Ocean ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = range(10)\n",
    "text_code = text_codes[indices]\n",
    "text_code[text_code == -1] = 0\n",
    "display(tokenizer.batch_decode(text_code))\n",
    "display(tokenizer.batch_decode(np.array(text_dataset[indices][\"text\"][\"input_ids\"])[:, :100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trie = TrieIndex(save_dir=f\"data/cache/{config.dataset}/codes/{code_type}/{code_tokenizer}/{code_length}\")\n",
    "# trie.load()\n",
    "\n",
    "# wordset = WordSetIndex(save_dir=f\"data/cache/{config.dataset}/codes/{code_type}/{code_tokenizer}/{code_length}\", sep_token_id=6)\n",
    "# wordset.fit(None)\n",
    "\n",
    "# text_codes = np.sort(text_codes, axis=-1)\n",
    "df = pd.DataFrame(text_codes)\n",
    "duplicates = df.groupby(df.columns.tolist(),as_index=False).size()\n",
    "duplicates = duplicates.sort_values(\"size\", ascending=False)\n",
    "duplicates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dup = df.duplicated(keep=\"first\").to_numpy()\n",
    "dup_indices = np.argwhere(dup)[:, 0]\n",
    "len(dup_indices), duplicates[\"size\"][duplicates[\"size\"] > 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "778a5a6b0df35a46498564cf16af2e5ec016022ef7dc9d5934de67fcb1f6bfb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
